---
title: "MyTrainingBuddy"
author: "Shiv"
date: "Tuesday, August 18, 2015"
output: html_document
---
MyTrainingBuddy is a machinelearning algorithm that learns how correctly a given gym excercise is done and grades your exercize into the right category. The report below illustrates the making of the MyTrainingBuddy.

MyTrainingBuddy is trained using a data provided by [groupware.les] http://groupware.les.inf.puc-rio.br/har. The data is already split as Training and Test Set. Training set would be used to train and test the data. While the original test set would be used to finally validate this data. Keeping one data set ( hence forth called the validation set) separately and using it once and only once to find the accuracy of the model implies that we do not use the validation set for training the model and avoid any overfitting errors.

***Load the dataset***

As a first step lets setup the enviroment, load the data set.

```{r}
WKDir="C:/Users/shivsood/Documents/GitHub/param/MachineLearning/CourseProject"
setwd(WKDir)
df<-read.csv("pml-training.csv",header=TRUE)
validationSet<-read.csv("pml-testing.csv",header=TRUE)
```
Note that `r nrow(df)` rows were loaded in this data set. 

***Partition Training and Test Set***

As a next step, first split the data as training and test set. Then use the training set for further exploration to understand features of the data that can be used for training. Note : That **classe** is a value that we wish to predict and that would be used to split the data into 2 sets.


```{r}
library(caret)
set.seed(02121976)
trainIndex=createDataPartition(df$classe,p=0.8,list=FALSE)
trainingSet=df[trainIndex,]
testSet=df[-trainIndex,]
```
From `r nrow(df)` rows of original data, the training set consist of `r nrow(trainingSet)` rows and testSet contains
`r nrow(testSet)` rows of data now.

***Clean/Scrub the Training Set***

At first lets explore the data by normal read out of the data. Some observations to make
- There are 3 type of variables - int, num and factors. Note : Factor variables need to be covereted before any applicaiton.
- Lots of variables seem are NA. Intresting to explore if there are features that have no avaialble values at all.
- 

```{r}
vFeaturesWithNoData=sapply(trainingSet,function(z) round(100*sum(!is.na(z))/nrow(trainingSet),2))
vColsWithNoData_ValidattionSet=sapply(validationSet,function(z) round(100*sum(!is.na(z))/nrow(validationSet),2))
```

We observe of a total of `r ncol(trainingSet)` features in the data set there are `r length(vFeaturesWithNoData[vFeaturesWithNoData!=100])` features with only `r mean(vFeaturesWithNoData[vFeaturesWithNoData!=100])`% non NA values. So we are looking at `r length(vFeaturesWithNoData[vFeaturesWithNoData!=100])` very sparse ( less density of data). The data needs to be cleaned to remove these as features.


Does test set have these features?
We observe of a total of `r ncol(validationSet)` features in the data set there are `r length(vColsWithNoData_ValidattionSet[vColsWithNoData_ValidattionSet!=100])` features with only `r mean(vColsWithNoData_ValidattionSet[vColsWithNoData_ValidattionSet!=100])`% non NA values. So we are looking at `r length(vColsWithNoData_ValidattionSet[vColsWithNoData_ValidattionSet!=100])` columns that are very sparse ( less density of data). "No data" is not a good input to the predictor,  so these should be removed out of the feature set as well.


Drop columns from the trainingSet that are do not have any data in the testSet.

```{r}
vNoDataColsInValidationSet=vColsWithNoData_ValidattionSet[vColsWithNoData_ValidattionSet!=100]
trainingSubSet=trainingSet[,-which(names(trainingSet) %in% names(vNoDataColsInValidationSet))]
```

In this reduced data set, lets look for features that have no data. These would not incluence the outcome and thus should be removed. Hoping to get no features with sparse data.

```{r}
vFeaturesWithNoData2=sapply(trainingSubSet,function(z) round(100*sum(!is.na(z))/nrow(trainingSubSet),2))
```

We observe of a total of `r ncol(trainingSubSet)` features in the data set there are `r length(vFeaturesWithNoData2[vFeaturesWithNoData2!=100])` features with 'NA' values. So we are now looking at a fully dense training data.

***Explore the data set***

The objective here is to find features that in the data set that could be used to train the model. A feature usually the subset of the predictors that exibit a high correlation to the prediction. 


```r{}
library(corrplot)
corMatrix = cor(traningSet[,c(1,3,4,7,8)])
corrplot(corMatrix, method="number")
```




